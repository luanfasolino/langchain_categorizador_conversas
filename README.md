# ğŸ¯ Categorizador de Conversas com IA

Sistema inteligente de categorizaÃ§Ã£o e anÃ¡lise de tickets de suporte ao cliente usando **LangChain** e **Google Gemini AI**. O sistema processa conversas em larga escala e gera categorias precisas seguindo uma arquitetura **Map-Reduce-Classify**.

## ğŸŒŸ Funcionalidades

- âœ… **CategorizaÃ§Ã£o Inteligente**: Classifica automaticamente tickets de suporte
- âœ… **AnÃ¡lise de PadrÃµes**: Identifica problemas recorrentes e tendÃªncias
- âœ… **Resumos Executivos**: Gera bullet points com sugestÃµes de melhoria
- âœ… **Cache Inteligente**: Sistema de cache para otimizar performance e custos
- âœ… **Processamento Paralelo**: ExecuÃ§Ã£o otimizada com mÃºltiplos workers
- âœ… **RelatÃ³rios Detalhados**: AnÃ¡lises completas com mÃ©tricas e custos

## ğŸ—ï¸ Como Funciona a CategorizaÃ§Ã£o

Nosso sistema segue uma arquitetura **Map-Reduce-Classify** inspirada em prÃ¡ticas de Big Data:

```
ğŸ“Š DADOS BRUTOS
      â†“
ğŸ”„ FASE MAP (Resumir)
   â€¢ Divide conversas em chunks
   â€¢ Cada chunk Ã© resumido em paralelo
   â€¢ Identifica problemas principais
      â†“
ğŸ”„ FASE REDUCE (Consolidar)
   â€¢ Combina todos os resumos
   â€¢ Cria visÃ£o unificada dos problemas
   â€¢ Identifica padrÃµes globais
      â†“
ğŸ¯ FASE CLASSIFY (Categorizar)
   â€¢ Usa anÃ¡lise consolidada
   â€¢ Categoriza cada ticket individualmente
   â€¢ Gera categorias especÃ­ficas e precisas
      â†“
ğŸ“ˆ RESULTADOS FINAIS
```

### ğŸ’¡ Por que essa Arquitetura?

1. **ğŸ¯ PrecisÃ£o**: CategorizaÃ§Ã£o baseada em anÃ¡lise completa do dataset
2. **âš¡ Performance**: Processamento paralelo otimizado
3. **ğŸ’° EficiÃªncia**: Cache inteligente reduz custos de API
4. **ğŸ” Qualidade**: VisÃ£o consolidada gera categorias mais consistentes

## ğŸš€ InÃ­cio RÃ¡pido

### ğŸ“‹ PrÃ©-requisitos

- Python 3.8+
- Conta Google Cloud com Gemini AI habilitado
- 4GB RAM mÃ­nimo (recomendado: 8GB)

### ğŸ”§ InstalaÃ§Ã£o

1. **Clone o repositÃ³rio:**
```bash
git clone <url-do-repositorio>
cd langchain_categorizador_conversas
```

2. **Crie um ambiente virtual:**
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate     # Windows
```

3. **Instale as dependÃªncias:**
```bash
pip install -r requirements.txt
```

4. **Configure sua API Key:**
```bash
# Crie um arquivo .env na raiz do projeto
echo "GOOGLE_API_KEY=sua_api_key_aqui" > .env
```

### ğŸ“Š PreparaÃ§Ã£o dos Dados

Seu arquivo CSV deve ter estas colunas obrigatÃ³rias:
- `ticket_id`: ID Ãºnico do ticket
- `category`: Tipo de mensagem (use 'TEXT' para conversas)
- `text`: ConteÃºdo da conversa
- `sender`: Quem enviou (USER, AGENT, HELPDESK_INTEGRATION, etc.)
- `ticket_created_at`: Data de criaÃ§Ã£o

**Exemplo:**
```csv
ticket_id;category;text;sender;ticket_created_at
12345;TEXT;OlÃ¡, preciso de ajuda;USER;2024-01-15 10:30:00
12345;TEXT;Como posso ajudÃ¡-lo?;AGENT;2024-01-15 10:31:00
```

Coloque seu arquivo na pasta `database/` (serÃ¡ criada automaticamente).

## ğŸ® Como Usar

### ğŸ”¥ ExecuÃ§Ã£o Completa (Recomendado)

Para processar um dataset completo:

```bash
python src/main.py --mode all --cache-control fresh
```

### ğŸ›ï¸ ExecuÃ§Ã£o por Etapas

Se preferir executar etapa por etapa:

```bash
# 1. Apenas categorizaÃ§Ã£o
python src/main.py --mode categorize --cache-control fresh

# 2. Apenas resumos e bullet points
python src/main.py --mode summarize --cache-control fresh

# 3. Combinar resultados
python src/main.py --mode merge

# 4. AnÃ¡lise completa e relatÃ³rios
python src/main.py --mode analyze
```

### âš™ï¸ OpÃ§Ãµes AvanÃ§adas

```bash
# Processar apenas primeiros 1000 registros (para testes)
python src/main.py --mode all --nrows 1000

# Usar menos workers (se tiver problemas de rate limit)
python src/main.py --mode all --workers 2

# Especificar arquivo especÃ­fico
python src/main.py --mode all --input-file "meu_arquivo.csv"

# Usar cache existente (mais rÃ¡pido)
python src/main.py --mode all --cache-control continue
```

## ğŸ¯ Controle de Cache

O sistema tem **cache inteligente** que acelera execuÃ§Ãµes subsequentes:

### ğŸš€ Fresh Start (MÃ¡xima PrecisÃ£o)
```bash
--cache-control fresh
```
- âŒ Apaga cache antigo
- âœ… Processa tudo novamente  
- âœ… Gera novo cache
- **Use quando:** Mudou prompts, dados ou quer mÃ¡xima precisÃ£o

### âš¡ Continue (MÃ¡xima Velocidade)  
```bash
--cache-control continue
```
- âœ… Usa cache existente
- âš¡ Processamento muito mais rÃ¡pido
- **Use quando:** Dados e configuraÃ§Ãµes nÃ£o mudaram

### ğŸš« Sem Cache
```bash
--no-cache
```
- âŒ NÃ£o usa cache existente
- âŒ NÃ£o salva novo cache
- **Use quando:** Quer sempre reprocessar tudo

## ğŸ“ Estrutura de Arquivos Gerados

ApÃ³s a execuÃ§Ã£o, vocÃª encontrarÃ¡:

```
database/
â”œâ”€â”€ cache/                              # Cache inteligente (acelera prÃ³ximas execuÃ§Ãµes)
â””â”€â”€ analysis_reports/                   # ğŸ“ Todos os arquivos de anÃ¡lise organizados aqui
    â”œâ”€â”€ categorized_tickets.csv         # Tickets categorizados
    â”œâ”€â”€ summarized_tickets.csv          # Bullet points de melhoria
    â”œâ”€â”€ summarized_tickets_resumo.txt   # Resumo executivo
    â”œâ”€â”€ final_analysis.csv              # AnÃ¡lise combinada
    â”œâ”€â”€ pipeline_analysis_YYYYMMDD_HHMMSS.xlsx     # RelatÃ³rio Excel completo
    â”œâ”€â”€ pipeline_analysis_YYYYMMDD_HHMMSS_categories.csv    # AnÃ¡lise por categorias
    â”œâ”€â”€ pipeline_analysis_YYYYMMDD_HHMMSS_summary.csv       # Resumo estatÃ­stico
    â””â”€â”€ pipeline_analysis_YYYYMMDD_HHMMSS_summary.txt       # Resumo executivo
```

## ğŸ“Š Interpretando os Resultados

### ğŸ·ï¸ Categorized Tickets
Arquivo com todas as categorias atribuÃ­das:
```csv
ticket_id;categoria
12345;Problema de Login
12345;RecuperaÃ§Ã£o de Senha
12346;DÃºvida sobre CobranÃ§a
```

### ğŸ’¡ Bullet Points
15 sugestÃµes prÃ¡ticas para reduzir volume de contatos:
```csv
bullet
Implementar reset de senha automÃ¡tico via SMS
Criar FAQ sobre problemas de login mais comuns
Melhorar interface de recuperaÃ§Ã£o de conta
```

### ğŸ“ˆ RelatÃ³rios de AnÃ¡lise
- **Categorias mais frequentes**
- **TendÃªncias por perÃ­odo**
- **Oportunidades de melhoria**
- **ROI estimado das melhorias**

## âš¡ Performance e Custos

### ğŸ¯ ConfiguraÃ§Ãµes Recomendadas

| Dataset | Workers | Tempo Estimado | Custo Estimado |
|---------|---------|----------------|----------------|
| 1K tickets | 2 | 10-15 min | $0.20-0.50 |
| 10K tickets | 4 | 1-2 horas | $2.00-5.00 |
| 100K tickets | 4 | 8-12 horas | $20-50 |

### ğŸ’° OtimizaÃ§Ã£o de Custos

1. **Use Cache**: Pode reduzir custos em 70-90%
2. **Workers Moderados**: 2-4 workers evitam rate limits
3. **Teste Pequeno**: Use `--nrows 100` para testar configuraÃ§Ãµes

## ğŸ”§ SoluÃ§Ã£o de Problemas

### âŒ Problemas Comuns

**"Rate Limit Exceeded"**
```bash
# SoluÃ§Ã£o: Reduza workers
python src/main.py --mode all --workers 2
```

**"Nenhum ticket vÃ¡lido encontrado"**
- Verifique se tem coluna `category='TEXT'`
- Certifique-se que hÃ¡ mensagens USER e AGENT suficientes
- Veja o relatÃ³rio de filtragem no inÃ­cio da execuÃ§Ã£o

**"JSON Parsing Error"**
- Normalmente resolvido automaticamente com retry
- Se persistir, reduza `--nrows` para testes

**Cache nÃ£o funciona**
- Verifique permissÃµes da pasta `database/cache/`
- Use `--cache-control fresh` para recriar cache

### ğŸ“ Suporte

Se tiver problemas:

1. **Verifique os logs**: O sistema mostra logs detalhados
2. **Teste com poucos dados**: Use `--nrows 100` primeiro
3. **Verifique API Key**: Certifique-se que estÃ¡ no arquivo `.env`

## ğŸ§  Arquitetura TÃ©cnica

### ğŸ”§ Componentes Principais

- **LangChain**: Framework para aplicaÃ§Ãµes com LLM
- **Google Gemini 2.5 Flash**: Modelo de IA para categorizaÃ§Ã£o
- **Cache Manager**: Sistema inteligente de cache
- **Base Processor**: Processamento paralelo otimizado
- **Cost Tracker**: Monitoramento de custos em tempo real

### ğŸ¯ CaracterÃ­sticas TÃ©cnicas

- **Thread-safe**: Processamento paralelo seguro
- **Error Recovery**: Retry automÃ¡tico com backoff exponencial
- **Token Optimization**: Chunking inteligente para mÃ¡xima eficiÃªncia
- **Memory Efficient**: Processa datasets grandes sem explodir memÃ³ria

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ licenciado sob a [LicenÃ§a MIT](LICENSE).

---

## ğŸ‰ ContribuiÃ§Ãµes

ContribuiÃ§Ãµes sÃ£o bem-vindas! Sinta-se Ã  vontade para:

- ğŸ› Reportar bugs
- ğŸ’¡ Sugerir melhorias
- ğŸ”§ Enviar pull requests
- ğŸ“š Melhorar documentaÃ§Ã£o

---

**Desenvolvido com â¤ï¸ usando LangChain e Google Gemini AI**